# üõ°Ô∏è M√≥dulo 6: √âtica y privacidad

El uso de herramientas de inteligencia artificial plantea importantes cuestiones √©ticas y de protecci√≥n de datos.  
Este m√≥dulo te ayudar√° a comprender los **riesgos**, las **responsabilidades** y las **buenas pr√°cticas** relacionadas con la privacidad y el uso √©tico de la IA en el entorno laboral.

---

## Riesgos de privacidad y confidencialidad al usar IA

Las IA como ChatGPT procesan texto, pero no tienen memoria privada dentro de la empresa.  
Esto significa que:

- No debes compartir **datos sensibles**: nombres completos de clientes, DNI, cuentas bancarias, contrase√±as, etc.
- Todo lo que se introduce en una IA p√∫blica puede ser almacenado y analizado por el proveedor, aunque sea de forma an√≥nima.
- Algunas plataformas permiten entrenar modelos internos, pero requieren configuraciones espec√≠ficas de seguridad.

**Ejemplo de mal uso:**
> "ChatGPT, redacta este contrato para el cliente Mar√≠a L√≥pez con NIF 98765432X y direcci√≥n Calle Mayor 25..."

---

## C√≥mo proteger informaci√≥n sensible y cumplir normativas

1. **Evita introducir datos personales o confidenciales** en herramientas abiertas.
2. **Consulta con IT o Legal** si necesitas usar IA para datos reales de la empresa.
3. **Utiliza IA local o privada** cuando sea posible (por ejemplo, Microsoft Copilot bajo pol√≠ticas internas).
4. **Avisa siempre** si un contenido ha sido generado con IA (transparencia).
5. **Cumple el RGPD y otras normativas** seg√∫n tu rol y los datos que manejes.

### Herramientas con enfoque seguro:
- Microsoft Copilot (M365)
- ChatGPT Team / Enterprise
- Plataformas con control de datos (locales o cloud privados)

---

## L√≠mites √©ticos del uso de la IA en contextos laborales

M√°s all√° de lo legal, hay l√≠mites que conviene respetar en cuanto a:

- **Representaci√≥n honesta del trabajo**: no presentar como propio algo 100% generado por IA sin revisi√≥n.
- **Evitar sesgos**: la IA puede reproducir estereotipos o discriminaciones si no se revisa.
- **No depender ciegamente de la tecnolog√≠a**: siempre debe haber supervisi√≥n humana.
- **Uso transparente**: si colaboras con IA, dilo cuando sea relevante.

**Ejemplo positivo:**
> "Este informe ha sido generado con la ayuda de una herramienta de IA y revisado por el equipo de contabilidad."

---

## Actividad pr√°ctica

> Reflexiona sobre c√≥mo usas actualmente herramientas de IA:  
> - ¬øHas introducido alguna vez informaci√≥n sensible sin darte cuenta?  
> - ¬øCu√°ndo consideras que ser√≠a poco √©tico usar una IA?  
> - ¬øC√≥mo puedes mejorar tu uso responsable a partir de ahora?

Escribe tus respuestas y comp√°rtelas en grupo si lo deseas.

---

## Recursos adicionales

- [Gu√≠a de privacidad y seguridad en IA (Agencia Espa√±ola de Protecci√≥n de Datos)](https://www.aepd.es/)
- [Principios √©ticos para la IA (Comisi√≥n Europea)](https://digital-strategy.ec.europa.eu/)
- [Normativa sobre uso de IA en el entorno laboral (PDF interno)](/oficina_basico/stuff/etica_privacidad_navima.pdf)

---

<p align="center">
  <a href="modulo_5.md">‚èÆÔ∏è M√≥dulo anterior</a>
</p>
